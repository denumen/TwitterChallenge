{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-05T17:48:05.863803Z",
     "iopub.status.busy": "2023-03-05T17:48:05.862485Z",
     "iopub.status.idle": "2023-03-05T17:48:05.870478Z",
     "shell.execute_reply": "2023-03-05T17:48:05.868774Z",
     "shell.execute_reply.started": "2023-03-05T17:48:05.863749Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T16:34:21.333454Z",
     "iopub.status.busy": "2023-03-05T16:34:21.332847Z",
     "iopub.status.idle": "2023-03-05T16:34:32.421880Z",
     "shell.execute_reply": "2023-03-05T16:34:32.420714Z",
     "shell.execute_reply.started": "2023-03-05T16:34:21.333416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.26.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T17:46:16.496560Z",
     "iopub.status.busy": "2023-03-05T17:46:16.496000Z",
     "iopub.status.idle": "2023-03-05T17:46:23.405660Z",
     "shell.execute_reply": "2023-03-05T17:46:23.403836Z",
     "shell.execute_reply.started": "2023-03-05T17:46:16.496516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape = (480000, 2)\n",
      "label distribution :\n",
      "1.0    240639\n",
      "0.0    239361\n",
      "Name: label, dtype: int64\n",
      "        label                                           sentence\n",
      "541200    0.0             @chrishasboobs AHHH I HOPE YOUR OK!!! \n",
      "750       0.0  @misstoriblack cool , i have no tweet apps  fo...\n",
      "766711    0.0  @TiannaChaos i know  just family drama. its la...\n",
      "285055    0.0  School email won't open  and I have geography ...\n",
      "705995    0.0                             upper airways problem \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file = \"/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv\"\n",
    "df = pd.read_csv(file, encoding='ISO-8859-1', usecols=[0,5], header=None)\\\n",
    "        .sample(frac=0.3, random_state=42)\n",
    "\n",
    "df.columns = ['label','sentence']\n",
    "df.label = df.label.apply(lambda x: np.float64(1) if x==4 else np.float64(x))\n",
    "\n",
    "print(\"df.shape =\",df.shape)\n",
    "print(f\"label distribution :\\n{df.label.value_counts()}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "\n",
    "checkpoint = \"google/mobilebert-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = TFAutoModel.from_pretrained(checkpoint, output_hidden_states=True)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T17:48:08.756261Z",
     "iopub.status.busy": "2023-03-05T17:48:08.755788Z",
     "iopub.status.idle": "2023-03-05T17:48:09.242631Z",
     "shell.execute_reply": "2023-03-05T17:48:09.241047Z",
     "shell.execute_reply.started": "2023-03-05T17:48:08.756223Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "sequences, test_val_sequences = train_test_split(df, test_size=0.3,\n",
    "                                             stratify=df.label, random_state=44)\n",
    "val_sequences, test_sequences = train_test_split(test_val_sequences, test_size=0.7,\n",
    "                                             stratify=test_val_sequences.label, random_state=44)\n",
    "dataset = {\n",
    "    \"TRAIN\": sequences['sentence'].values.tolist(),\n",
    "    \"TEST\": test_sequences['sentence'].values.tolist(),\n",
    "    \"VAL\": val_sequences['sentence'].values.tolist()\n",
    "}\n",
    "targets = {\n",
    "    \"TRAIN\": sequences['label'].values.tolist(),\n",
    "    \"TEST\": test_sequences['label'].values.tolist(),\n",
    "    \"VAL\": val_sequences['label'].values.tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T17:48:09.885749Z",
     "iopub.status.busy": "2023-03-05T17:48:09.884241Z",
     "iopub.status.idle": "2023-03-05T17:48:09.895352Z",
     "shell.execute_reply": "2023-03-05T17:48:09.893653Z",
     "shell.execute_reply.started": "2023-03-05T17:48:09.885682Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenization(data, **kwargs):\n",
    "    return tokenizer(data, \n",
    "                   padding=kwargs.get('padding','longest'), \n",
    "                   max_length=kwargs.get('max_length',55),\n",
    "                   truncation=True, \n",
    "                   return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T17:48:10.407401Z",
     "iopub.status.busy": "2023-03-05T17:48:10.406915Z",
     "iopub.status.idle": "2023-03-05T17:48:10.420017Z",
     "shell.execute_reply": "2023-03-05T17:48:10.418254Z",
     "shell.execute_reply.started": "2023-03-05T17:48:10.407339Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(**kwargs):\n",
    "    global model\n",
    "    max_seq_length = kwargs.get('max_seq_length',55)\n",
    "\n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained('google/mobilebert-uncased')\n",
    "    \n",
    "\n",
    "    input_ids = tf.keras.Input(shape=(max_seq_length,), dtype='int32', name='input_ids')\n",
    "    attention_mask = tf.keras.Input(shape=(max_seq_length,), dtype='int32', name='attention_mask')\n",
    "\n",
    "    # Tokenize inputs and pass them through the MobileBERT model\n",
    "    inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "    outputs = model(inputs)\n",
    "    pooler_output = outputs['pooler_output']\n",
    "\n",
    "    # Model Head\n",
    "    h1 = tf.keras.layers.Dense(128, activation='relu')(pooler_output)\n",
    "    dropout = tf.keras.layers.Dropout(0.2)(h1)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(dropout)\n",
    "\n",
    "    # Create and compile the new model\n",
    "    new_model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    metrics = [tf.keras.metrics.BinaryAccuracy()]\n",
    "    new_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T17:48:10.834881Z",
     "iopub.status.busy": "2023-03-05T17:48:10.833358Z",
     "iopub.status.idle": "2023-03-05T17:48:10.855487Z",
     "shell.execute_reply": "2023-03-05T17:48:10.847305Z",
     "shell.execute_reply.started": "2023-03-05T17:48:10.834799Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def test_result(model):    \n",
    "    test_inputs = tokenization(dataset[\"TEST\"])\n",
    "    result_proba = model.predict([test_inputs.input_ids, test_inputs.attention_mask])\n",
    "    result = [1 if x>0.5 else 0 for x in result_proba.ravel()]\n",
    "    print(classification_report(targets['TEST'],result))\n",
    "    return result_proba, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T17:48:11.882164Z",
     "iopub.status.busy": "2023-03-05T17:48:11.880427Z",
     "iopub.status.idle": "2023-03-05T17:48:33.590015Z",
     "shell.execute_reply": "2023-03-05T17:48:33.588582Z",
     "shell.execute_reply.started": "2023-03-05T17:48:11.882081Z"
    }
   },
   "outputs": [],
   "source": [
    "new_model = get_model()\n",
    "#result_proba_before, result_before = test_result(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T17:48:37.990636Z",
     "iopub.status.busy": "2023-03-05T17:48:37.989746Z",
     "iopub.status.idle": "2023-03-05T21:41:33.139954Z",
     "shell.execute_reply": "2023-03-05T21:41:33.138444Z",
     "shell.execute_reply.started": "2023-03-05T17:48:37.990591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2625/2625 [==============================] - 1272s 369ms/step - loss: 12513.8262 - binary_accuracy: 0.6402 - val_loss: 0.5832 - val_binary_accuracy: 0.6972\n",
      "Epoch 2/100\n",
      "2625/2625 [==============================] - 918s 350ms/step - loss: 0.5764 - binary_accuracy: 0.6976 - val_loss: 0.5410 - val_binary_accuracy: 0.7223\n",
      "Epoch 3/100\n",
      "2625/2625 [==============================] - 911s 347ms/step - loss: 0.5456 - binary_accuracy: 0.7227 - val_loss: 0.5157 - val_binary_accuracy: 0.7435\n",
      "Epoch 4/100\n",
      "2625/2625 [==============================] - 911s 347ms/step - loss: 0.5149 - binary_accuracy: 0.7461 - val_loss: 0.4843 - val_binary_accuracy: 0.7666\n",
      "Epoch 5/100\n",
      "2625/2625 [==============================] - 913s 348ms/step - loss: 0.4728 - binary_accuracy: 0.7760 - val_loss: 0.4421 - val_binary_accuracy: 0.7927\n",
      "Epoch 6/100\n",
      "2625/2625 [==============================] - 906s 345ms/step - loss: 0.4268 - binary_accuracy: 0.8044 - val_loss: 0.4070 - val_binary_accuracy: 0.8148\n",
      "Epoch 7/100\n",
      "2625/2625 [==============================] - 911s 347ms/step - loss: 0.3897 - binary_accuracy: 0.8258 - val_loss: 0.3779 - val_binary_accuracy: 0.8292\n",
      "Epoch 8/100\n",
      "2625/2625 [==============================] - 912s 347ms/step - loss: 0.3577 - binary_accuracy: 0.8426 - val_loss: 0.3562 - val_binary_accuracy: 0.8416\n",
      "Epoch 9/100\n",
      "2625/2625 [==============================] - 910s 347ms/step - loss: 0.3555 - binary_accuracy: 0.8462 - val_loss: 0.3576 - val_binary_accuracy: 0.8435\n",
      "Epoch 10/100\n",
      "2625/2625 [==============================] - 909s 346ms/step - loss: 0.3193 - binary_accuracy: 0.8630 - val_loss: 0.3465 - val_binary_accuracy: 0.8498\n",
      "Epoch 11/100\n",
      "2625/2625 [==============================] - 864s 329ms/step - loss: 0.3713 - binary_accuracy: 0.8701 - val_loss: 0.3569 - val_binary_accuracy: 0.8476\n",
      "Epoch 12/100\n",
      "2625/2625 [==============================] - 883s 336ms/step - loss: 0.2738 - binary_accuracy: 0.8854 - val_loss: 0.3563 - val_binary_accuracy: 0.8488\n",
      "Epoch 13/100\n",
      "2625/2625 [==============================] - 897s 342ms/step - loss: 0.2363 - binary_accuracy: 0.9033 - val_loss: 0.3799 - val_binary_accuracy: 0.8449\n",
      "Epoch 14/100\n",
      "2625/2625 [==============================] - 909s 346ms/step - loss: 0.2112 - binary_accuracy: 0.9144 - val_loss: 0.4226 - val_binary_accuracy: 0.8432\n",
      "Epoch 15/100\n",
      "2625/2625 [==============================] - 909s 346ms/step - loss: 0.1946 - binary_accuracy: 0.9218 - val_loss: 0.4931 - val_binary_accuracy: 0.8442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b191fb390>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenization(dataset['TRAIN'])\n",
    "train_targets = tf.convert_to_tensor(targets['TRAIN'])\n",
    "\n",
    "val_inputs = tokenization(dataset['VAL'])\n",
    "val_targets = tf.convert_to_tensor(targets['VAL'])\n",
    "\n",
    "# Train the model\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', mode='max', patience=5)\n",
    "\n",
    "new_model.fit([inputs.input_ids, inputs.attention_mask], train_targets, \n",
    "              validation_data = ([val_inputs.input_ids, val_inputs.attention_mask], val_targets),\n",
    "              epochs=100, batch_size=128, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T21:57:56.431142Z",
     "iopub.status.busy": "2023-03-05T21:57:56.429409Z",
     "iopub.status.idle": "2023-03-05T22:00:44.215228Z",
     "shell.execute_reply": "2023-03-05T22:00:44.213737Z",
     "shell.execute_reply.started": "2023-03-05T21:57:56.431057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3150/3150 [==============================] - 125s 36ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.84     50266\n",
      "         1.0       0.85      0.83      0.84     50534\n",
      "\n",
      "    accuracy                           0.84    100800\n",
      "   macro avg       0.84      0.84      0.84    100800\n",
      "weighted avg       0.84      0.84      0.84    100800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_proba_after, result_after = test_result(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T21:57:32.764256Z",
     "iopub.status.busy": "2023-03-05T21:57:32.762796Z",
     "iopub.status.idle": "2023-03-05T21:57:42.127769Z",
     "shell.execute_reply": "2023-03-05T21:57:42.125972Z",
     "shell.execute_reply.started": "2023-03-05T21:57:32.764182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  adding: sentiment_weights_MobileBert_final.h5 (deflated 8%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='sentiment_weights_MobileBert_final.zip' target='_blank'>sentiment_weights_MobileBert_final.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/sentiment_weights_MobileBert_final.zip"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAVE MODEL WEIGHTS\n",
    "new_model.save_weights(f'sentiment_weights_MobileBert_final.h5')\n",
    "!zip -r sentiment_weights_MobileBert_final.zip sentiment_weights_MobileBert_final.h5\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'sentiment_weights_MobileBert_final.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
